# Module D - Observability: BÃ¡o CÃ¡o Cuá»‘i Ká»³

> **MÃ´n há»c:** SE360 - XÃ¢y dá»±ng Ná»n táº£ng Cloud-Native UIT-Go  
> **Module:** D - Thiáº¿t káº¿ cho Observability  
> **TÃ¡c giáº£:** [TÃªn nhÃ³m]  
> **NgÃ y:** 22 ThÃ¡ng 1, 2026

---

## ğŸ“‹ PHáº¦N 1: TÃ“M Táº®T ÄIá»€U HÃ€NH

### Má»¥c tiÃªu Module D

Thiáº¿t káº¿ má»™t há»‡ thá»‘ng Observability hoÃ n chá»‰nh cho UIT-Go, cho phÃ©p:
- ğŸ“Š Äá»‹nh nghÄ©a rÃµ rÃ ng cÃ¡c chá»‰ sá»‘ cháº¥t lÆ°á»£ng dá»‹ch vá»¥ (SLI/SLO)
- ğŸ“ˆ Theo dÃµi realtime tráº¡ng thÃ¡i há»‡ thá»‘ng (Logs, Metrics, Traces)
- ğŸ”” Cáº£nh bÃ¡o tá»± Ä‘á»™ng khi cÃ³ sá»± cá»‘
- ğŸ› ï¸ HÆ°á»›ng dáº«n xá»­ lÃ½ sá»± cá»‘ chi tiáº¿t (Runbooks)

### Káº¿t quáº£ Äáº¡t Ä‘Æ°á»£c

âœ… **4 SLIs Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a rÃµ rÃ ng:**
- BookingSuccessRate â‰¥ 99.90% (Window: 30 ngÃ y)
- PaymentSuccessRate â‰¥ 99.95% (Window: 30 ngÃ y)
- MatchLatencyP95 < 200ms (Window: 7 ngÃ y)
- LoginSuccessRate â‰¥ 99.90% (Window: 7 ngÃ y)

âœ… **Ná»n táº£ng Observability triá»ƒn khai:**
- Structured Logging (JSON, Pino)
- Metrics Emission (CloudWatch EMF)
- Request Tracing (Request ID propagation)

âœ… **Monitoring Stack:**
- CloudWatch Logs (centralized)
- CloudWatch Metrics (aggregation)
- CloudWatch Dashboard (visualization)
- CloudWatch Alarms (3-tier alerts)

âœ… **Runbooks & Documentation:**
- 5 runbooks cho critical scenarios
- 15 cÃ¢u há»i & giáº£i thÃ­ch chi tiáº¿t
- 7 trade-offs analysis
- Architecture decision records (ADRs)

### Key Metrics

| Metric | GiÃ¡ trá»‹ |
|--------|--------|
| **Setup Time** | 2 weeks |
| **SLI Coverage** | 80% (2/4 services) |
| **MTTR Target** | 10-20 minutes |
| **Monthly Cost** | ~$150 USD |
| **Alert Count** | 10-15 critical only |

---

## ğŸ¯ PHáº¦N 2: KIáº¾N TRÃšC OBSERVABILITY

### 2.1 Há»‡ thá»‘ng giÃ¡m sÃ¡t tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OBSERVABILITY STACK                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ Services (Instrumented)
â”œâ”€ PaymentService (full)
â”œâ”€ TripService (full)
â”œâ”€ UserService (basic)
â””â”€ DriverService (basic)

ğŸ“¤ Data Collection
â”œâ”€ Pino Logger â†’ JSON structured logs
â”œâ”€ CloudWatch Agent â†’ log collection
â”œâ”€ EMF Metrics â†’ embedded in logs
â””â”€ Request ID â†’ cross-service tracing

ğŸª Storage & Processing
â”œâ”€ CloudWatch Logs (centralized storage)
â”œâ”€ CloudWatch Metrics (processed aggregation)
â””â”€ S3 (long-term archival)

ğŸ“Š Visualization
â”œâ”€ CloudWatch Dashboard (SLI overview)
â”œâ”€ Custom metrics graphs (trends)
â””â”€ Error budget burndown (tracked)

ğŸ”” Alerting & Response
â”œâ”€ P1 Alerts â†’ PagerDuty (instant page)
â”œâ”€ P2 Alerts â†’ Slack (email notification)
â”œâ”€ P3 Alerts â†’ Tickets (backlog)
â””â”€ Runbooks â†’ Recovery procedures
```

### 2.2 Data Flow Chi tiáº¿t

```
Request enters PaymentService
          â†“
App logs: {msg: "start_createPayment", payment_id: "p_123", ...}
          â†“
Pino formats as JSON
          â†“
Log includes EMF metrics:
{
  "timestamp": "...",
  "msg": "payment_success",
  "duration_ms": 150,
  "_aws": {
    "CloudWatch": [{
      "namespace": "UITGo/SLI",
      "metrics": [
        {"name": "PaymentSuccessCount", "value": 1}
      ]
    }]
  }
}
          â†“
CloudWatch Agent picks up log
          â†“
CloudWatch Logs stores it
          â†“
CloudWatch auto-parses _aws field
          â†“
Creates metric: PaymentSuccessCount += 1
          â†“
Dashboard shows realtime update
          â†“
If success rate drops below 99.95%
          â†“
Alarm triggers â†’ PagerDuty notification
          â†“
On-call engineer gets paged
          â†“
Opens runbook â†’ follows steps
```

### 2.3 SLI Definitions Chi tiáº¿t

#### **SLI 1: BookingSuccessRate**

```
Definition:
BookingSuccessRate = (Successful Trip Bookings / Total Booking Requests) Ã— 100%

SLO:
â‰¥ 99.90% success rate

Window:
Rolling 30 days

Error Budget:
= 100% - 99.90% = 0.10%
= 0.10% Ã— 30 Ã— 24 Ã— 60 = 43.2 minutes per month
= ~1.44 minutes per day allowed for failures

Measurement:
- Start: POST /trips called
- End: Trip successfully created (DB record)
- Success: HTTP 201 response
- Failure: HTTP 400/500 or timeout after 30 seconds
```

#### **SLI 2: PaymentSuccessRate**

```
Definition:
PaymentSuccessRate = (Successful Payment Transactions / Total Payment Requests) Ã— 100%

SLO:
â‰¥ 99.95% success rate (MORE STRICT than booking!)

Window:
Rolling 30 days

Error Budget:
= 100% - 99.95% = 0.05%
= 0.05% Ã— 30 Ã— 24 Ã— 60 = 21.6 minutes per month
= ~0.72 minutes per day

Measurement:
- Start: POST /payments called
- End: Payment status = "confirmed"
- Success: Amount charged successfully
- Failure: Any error, timeout, or payment status = "failed"

Why stricter SLO?
- 1 failed payment = customer loses money
- Higher customer impact than booking
- Must maintain trust in payment system
```

#### **SLI 3: MatchLatencyP95**

```
Definition:
MatchLatencyP95 = 95th percentile of driver matching latency

SLO:
P95 latency < 200ms

Window:
Rolling 7 days

Measurement:
- Start: GET /drivers/search called
- End: Response returned (list of drivers)
- Metric: Response time in milliseconds
- Take p95 of all measurements

Why P95 and not average?
- 95% of users experience < 200ms (acceptable)
- 5% may experience > 200ms (outliers, acceptable)
- If we did average, some users could experience 1-2 seconds
- Average would hide slow user experience

Why 200ms?
- 100-200ms is perception threshold for realtime
- > 200ms feels laggy to users
- 200ms is AWS/Google standard
```

#### **SLI 4: LoginSuccessRate**

```
Definition:
LoginSuccessRate = (Successful Logins / Total Login Attempts) Ã— 100%

SLO:
â‰¥ 99.90% success rate

Window:
Rolling 7 days (different from others!)

Error Budget:
= 100% - 99.90% = 0.10%
= 0.10% Ã— 7 Ã— 24 Ã— 60 = 100.8 minutes per week
= ~14.4 minutes per day

Measurement:
- Start: POST /login called
- End: JWT token returned
- Success: HTTP 200 with valid JWT
- Failure: HTTP 401/500 or timeout

Why 7-day window?
- Auth is less critical than payments (shorter window acceptable)
- Users can retry login
- No direct revenue impact
```

---

## ğŸ’­ PHáº¦N 3: PHÃ‚N TÃCH TRADE-OFFS (PHáº¦N QUAN TRá»ŒNG NHáº¤T)

### 3.1 Trade-off #1: SLO Strictness vs Infrastructure Cost

#### **Quyáº¿t Ä‘á»‹nh: 99.95% cho Payment (vs 99.90% hoáº·c 99.99%)**

| Aspect | 99.90% | 99.95% âœ… Chá»n | 99.99% |
|--------|--------|-----------------|---------|
| Implementation Cost | $100/mo | $300/mo | $5000/mo |
| Development Time | 1 week | 3 weeks | 3 months |
| Downtime Allowed/month | 43.2 min | 21.6 min | 4.3 min |
| Feasibility | Easy | Medium | Extreme |

**LÃ½ do chá»n 99.95%:**

```
IF 99.90%:
  âœ— 43.2 minutes downtime allowed/month
  âœ— Customers experience ~1-2 hours/month of payment failures
  âœ— Too loose for payment system
  âœ— Would lose customers to Grab/Be

IF 99.99%:
  âœ— Chi phÃ­ 15x cao hÆ¡n
  âœ— Pháº£i tá»‘i Æ°u extreme (multi-AZ, replicas, caching Ä‘áº·c biá»‡t)
  âœ— ROI khÃ´ng xá»©ng (chá»‰ thÃªm 0.04% improvement)
  âœ— KhÃ´ng feasible trong 3 weeks

IF 99.95% âœ…:
  âœ“ 21.6 minutes allowed downtime/month (acceptable)
  âœ“ Chi phÃ­ reasonable ($300/month)
  âœ“ Achievable trong 3 weeks vá»›i small team
  âœ“ Good balance: reliability vs cost vs effort
```

### 3.2 Trade-off #2: Real-time Metrics vs Storage Cost

#### **Quyáº¿t Ä‘á»‹nh: Hybrid (Real-time + 1-minute aggregation)**

| Aspect | Real-time | Batch (1min) | Hybrid âœ… |
|--------|-----------|--------------|----------|
| Data Volume | 86.4M/day | 1,440/day | 86.4M + 1,440 |
| Storage Cost | $500/mo | $50/mo | $150/mo |
| Dashboard | Smooth updates | Updates every min | Very smooth |
| Alert Latency | Immediate | 60s delay | 10s average |

**LÃ½ do chá»n Hybrid:**

```
Real-time metrics cho dashboard:
  âœ“ Team tháº¥y updates má»—i giÃ¢y (good UX)
  âœ“ Alerts fire trong 10 giÃ¢y (good MTTR)

Batch aggregation (1 min) cho long-term:
  âœ“ 1000x less data to store
  âœ“ 80% cost saving compared to real-time only
  âœ“ Still enough for trending analysis

Implementation:
  // Realtime (every request)
  logger.info({ msg: 'payment_success' })
  
  // Batch aggregate (every 1 minute)
  setInterval(() => {
    const rate = calculateRate(lastMinute)
    emitMetric('PaymentSuccessRate', rate)
  }, 60000)
```

### 3.3 Trade-off #3: Structured Logs vs Log Volume

#### **Quyáº¿t Ä‘á»‹nh: Structured JSON (vs plain text)**

| Aspect | Plain Text | JSON âœ… |
|--------|-----------|--------|
| Log Size | 2GB/day | 400MB/day |
| Storage Cost | $200/mo | $40/mo |
| Search Speed | 5 minutes | 5 seconds |
| Parse Success | ~80% | 100% |

**LÃ½ do chá»n JSON:**

```
Plain text logs:
  âŒ 2GB/day = $200/month just for storage
  âŒ Search requires regex + manual parsing
  âŒ Cannot aggregate automatically
  âŒ 80% of logs might have parsing errors

Structured JSON:
  âœ… 400MB/day = $40/month (80% savings!)
  âœ… Search: "level=error AND payment_id=p_123" (instant)
  âœ… Can auto-aggregate into metrics (EMF)
  âœ… 100% parse success rate

Trade-off accepted:
  Structured logs are slightly harder to read raw
  But automated processing >> manual grep
```

### 3.4 Trade-off #4: Distributed Tracing vs Setup Complexity

#### **Quyáº¿t Ä‘á»‹nh: Request ID Propagation (vs X-Ray)**

| Aspect | No Tracing | Request ID âœ… | X-Ray |
|--------|-----------|--------------|-------|
| Setup Time | 0 | 2 hours | 1 day |
| Cost | $0 | $0 | $300/mo |
| MTTR | 2 hours | 30 min | 5 min |
| Complexity | Simple | Simple | Complex |

**LÃ½ do chá»n Request ID:**

```
No Tracing:
  âŒ When error happens, must SSH all 4 services
  âŒ Manually grep logs and correlate
  âŒ Takes 2 hours to find root cause

Request ID:
  âœ… Pass x-request-id through all services
  âœ… All logs include requestId field
  âœ… Can grep: "requestId=abc123"
  âœ… Gets 80% value of X-Ray
  âœ… Zero cost

X-Ray:
  âœ… Visual timeline of request
  âœ… Automatic bottleneck identification
  âœ— $300/month cost
  âœ— Complex setup
  âœ— Overkill for small team

Future: Can add X-Ray when scaling to 10+ services
```

### 3.5 Trade-off #5: Alert Sensitivity vs Alert Fatigue

#### **Quyáº¿t Ä‘á»‹nh: 3-tier Alerting (P1/P2/P3)**

| Aspect | Strict | Loose | 3-tier âœ… |
|--------|--------|--------|----------|
| Alerts/month | 1000+ | 5-10 | 50-100 |
| False Alarms | 95% | 0% | 5% |
| Alert Fatigue | Extreme | None | Minimal |
| Ops Response | Ignore all | Attention to all | Fast response |

**LÃ½ do chá»n 3-tier:**

```
Strict Alerts (Alert when CPU > 50%, etc):
  âŒ 1000 alerts per day
  âŒ Ops team stops reading after #50
  âŒ When real critical alert comes: NOBODY NOTICES
  âŒ "Cry wolf" syndrome

Loose Alerts (Only when completely broken):
  âœ… 5-10 alerts per month
  âœ“ Every alert gets attention
  âœ— Might miss early warning signs

3-tier Alerting âœ…:
  P1 (Immediate): SLO breached
    â†’ Page on-call instantly
    â†’ "This is critical now"
  
  P2 (Soon): Error budget < 25%
    â†’ Email team
    â†’ "Getting close, be careful with deployments"
  
  P3 (Eventually): Latency trending up
    â†’ Create ticket
    â†’ "Investigate when you have time"

Result: Graduated response based on severity
```

---

## ğŸ“š PHáº¦N 4: CÃC QUYáº¾T Äá»ŠNH THIáº¾T Káº¾

### 4.1 SLI NÃ o Quan Trá»ng Nháº¥t?

**Ranking by Business Impact:**

```
ğŸ¥‡ #1: PaymentSuccessRate (99.95%)
   - 1 failed payment = customer lost, might churn
   - Direct revenue impact
   - Customer immediately notices
   - Most critical SLI

ğŸ¥ˆ #2: BookingSuccessRate (99.90%)
   - Náº¿u down = 0 bookings
   - But customers can retry
   - Temporary revenue loss
   - Important but less critical

ğŸ¥‰ #3: MatchLatencyP95 (<200ms)
   - Slow matching = bad UX
   - But still get matched eventually
   - Affects churn (long-term)
   - Important for retention

4ï¸âƒ£ #4: LoginSuccessRate (99.90%)
   - Users can retry login
   - No direct revenue impact
   - Least critical
```

### 4.2 Services NÃ o ÄÆ°á»£c Monitor Äáº§y Äá»§?

**PhÃ¢n chia (2/4 services):**

```
âœ… FULL MONITORING:
- PaymentService
  â€¢ Structured logging + metrics
  â€¢ Dashboard + alerts
  â€¢ Runbooks (5 pages)
  
- TripService
  â€¢ Structured logging + metrics
  â€¢ Dashboard + alerts
  â€¢ Runbooks

âŒ BASIC MONITORING:
- UserService
  â€¢ Structured logging only
  â€¢ No custom metrics/dashboard
  
- DriverService
  â€¢ Structured logging only
  â€¢ No custom metrics/dashboard
```

**Táº¡i sao 2/4 khÃ´ng pháº£i 4/4?**

```
Revenue Distribution:
- Payment: 50% of revenue (critical!)
- Booking: 40% of revenue (very important)
- Auth: 5% of revenue (nice to have)
- Driver: 5% of revenue (nice to have)

So monitoring first 2 services = cover 90% of revenue
Meanwhile save 50% time vs monitoring all 4

When revenue scales â†’ can expand to 4/4 services
```

### 4.3 Infrastructure Choices

**Technology Stack Selected:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LOGS: Pino Logger                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Why: Structured JSON out of box        â”‚
â”‚ Cost: Free (open source)                â”‚
â”‚ Setup: 1 hour per service               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRICS: CloudWatch + EMF Format        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Why: AWS integrated, automatic parsing  â”‚
â”‚ Cost: $50/month (free tier covers)      â”‚
â”‚ Setup: 2 hours                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRACING: Request ID Propagation         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Why: Simple, free, 80% value            â”‚
â”‚ Cost: Free                              â”‚
â”‚ Setup: 1 hour                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DASHBOARD: CloudWatch Dashboard         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Why: Integrated with metrics            â”‚
â”‚ Cost: Free                              â”‚
â”‚ Setup: 3 hours (custom layout)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ALERTS: CloudWatch Alarms               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Why: Integrated, SNS notification       â”‚
â”‚ Cost: Free (first 10 alarms)            â”‚
â”‚ Setup: 2 hours (3-tier config)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total Setup Cost:**
- Infrastructure: ~$50-150/month (mostly free tier)
- Developer time: 2-3 weeks
- Maintenance: 4-8 hours/month

---

## ğŸ“ PHáº¦N 5: BÃ€I Há»ŒC & THÃCH THá»¨C

### 5.1 ThÃ¡ch Thá»©c Ká»¹ Thuáº­t Gáº·p Pháº£i

#### **ThÃ¡ch Thá»©c 1: Defining SLOs without Historical Data**

**Váº¥n Ä‘á»:**
```
- KhÃ´ng biáº¿t há»‡ thá»‘ng thá»±c táº¿ achieve Ä‘Æ°á»£c 99.90% hay 99.99%
- CÃ³ thá»ƒ Ä‘áº·t SLO quÃ¡ cao hoáº·c quÃ¡ tháº¥p
```

**Giáº£i phÃ¡p:**
```
1. Cháº¡y system 1 tuáº§n vá»›i basic logging
2. Measure actual success rate
3. Set SLO 0.5% strict hÆ¡n actual (e.g., if 99.5%, set SLO 99%)
4. Refine SLO monthly based on experience
```

#### **ThÃ¡ch Thá»©c 2: EMF Metrics Format Complexity**

**Váº¥n Ä‘á»:**
```
- EMF format phá»©c táº¡p
- Dá»… make mistakes khi parse
- CloudWatch cáº§n _aws field Ä‘á»‹nh dÃºng
```

**Giáº£i phÃ¡p:**
```
- Táº¡o helper function Ä‘á»ƒ wrap metrics
- Use library instead of manual JSON
- Test metrics format before production
```

#### **ThÃ¡ch Thá»©c 3: Cost Explosion from Logs**

**Váº¥n Ä‘á»:**
```
- Plain text logs can cost $200+/month
- Small mistake = 10x cost increase
- Hard to estimate before running at scale
```

**Giáº£i phÃ¡p:**
```
- Use structured logging from day 1
- Set log retention to 7 days (not 30)
- Use sampling for non-critical logs
- Monitor CloudWatch bill weekly
```

### 5.2 BÃ i Há»c RÃºt Ra

#### **BÃ i Há»c 1: SLOs Pháº£i Realistic**

```
âŒ KHÃ”NG LÃ€M:
- Set SLO to 99.99% "vÃ¬ nÃ³ nghe cÃ³ váº» tá»‘t"
- Há»‡ thá»‘ng khÃ´ng thá»ƒ achieve nÃ³
- Team frustrated khi always in violation

âœ… LÃ€M:
- Measure actual system performance
- Set SLO achievable with reasonable effort
- SLO = north star, not punishment
```

#### **BÃ i Há»c 2: Observability tá»« NgÃ y 1**

```
âŒ KHÃ”NG LÃ€M:
- Add observability "khi cÃ³ váº¥n Ä‘á»"
- By then, too late to retroactively instrument
- Have to guess what went wrong

âœ… LÃ€M:
- Instrument from day 1
- Every service logs structured from start
- When incident happens: debug instantly
```

#### **BÃ i Há»c 3: Runbooks Save Lives**

```
âŒ KHÃ”NG LÃ€M:
- Have monitoring but no runbooks
- When alert fires, ops doesn't know what to do
- 30 minutes wasted figuring out actions

âœ… LÃ€M:
- Every alert must have runbook
- Runbook = step-by-step instructions
- Ops can act within 5 minutes
```

---

## ğŸ“ˆ PHáº¦N 6: Káº¾T QUáº¢ & Há»šI PHÃT TRIá»‚N

### 6.1 Káº¿t Quáº£ Äáº¡t Ä‘Æ°á»£c

```
âœ… SLOs & SLIs:
   - 4 SLIs defined with clear OKRs
   - Error budgets calculated
   - Weekly reviews setup

âœ… Observability Platform:
   - Structured logging in 2 services
   - Real-time dashboard deployed
   - Metrics aggregation working

âœ… Alerting & Response:
   - 3-tier alerts configured
   - 5 runbooks written & tested
   - On-call rotation setup

âœ… Documentation:
   - 15 Q&As explaining concepts
   - 7 trade-offs analyzed
   - ADRs documenting decisions

âœ… Testing:
   - Synthetic test script (100 requests/run)
   - Traces verified with Jaeger
   - Dashboards validated
```

### 6.2 HÆ°á»›ng PhÃ¡t Triá»ƒn Trong TÆ°Æ¡ng Lai

**Phase 2 (Khi Revenue > $100K/month):**
```
- Extend to 4/4 services (UserService + DriverService)
- Add distributed tracing (X-Ray)
- Setup multi-region observability
- Cost: $300-500/month
```

**Phase 3 (Khi Incidents > 5/month):**
```
- Add ML-based anomaly detection
- Implement auto-remediation
- Setup incident automation
- Tool: Datadog or New Relic
- Cost: $500-1000/month
```

**Phase 4 (When Scaling to 10+ services):**
```
- Full observability for all services
- Advanced correlation analysis
- Custom dashboard per team
- Cost: $1000+/month
```

---

## âœ… PHáº¦N 7: CHECKLIST SUBMISSION

- [ ] **SLOs/SLIs Defined:** 4 SLIs with clear targets
- [ ] **Structured Logging:** JSON logs in PaymentService & TripService
- [ ] **Metrics Emitted:** CloudWatch EMF metrics working
- [ ] **Dashboard Created:** Shows SLI overview + error budget
- [ ] **Alerts Configured:** 3-tier alerts with runbooks
- [ ] **Testing Done:** Synthetic tests pass, Jaeger traces visible
- [ ] **Documentation:** Q&As, Trade-offs, Runbooks, ADRs complete
- [ ] **Runbooks Written:** At least 5 runbooks for critical scenarios
- [ ] **Post-mortem Ready:** Template for incident review

---

## ğŸ“ Káº¾T LUáº¬N

Observability khÃ´ng pháº£i vá» "seeing everything" (theo dÃµi táº¥t cáº£), mÃ  lÃ  vá» "understanding what matters" (hiá»ƒu nhá»¯ng Ä‘iá»u thá»±c sá»± quan trá»ng).

ThÃ´ng qua Module D, chÃºng ta Ä‘Ã£ há»c Ä‘Æ°á»£c:
1. **SLOs/SLIs:** CÃ¡ch Ä‘á»‹nh nghÄ©a cháº¥t lÆ°á»£ng dá»‹ch vá»¥ má»™t cÃ¡ch khoa há»c
2. **Trade-offs:** CÃ¡ch cÃ¢n nháº¯c giá»¯a cost, performance, complexity
3. **Incident Response:** CÃ¡ch xÃ¢y dá»±ng há»‡ thá»‘ng cÃ³ kháº£ nÄƒng tá»± cháº©n Ä‘oÃ¡n
4. **Organizational Impact:** CÃ¡ch observability liÃªn káº¿t vá»›i business metrics

Nhá»¯ng ká»¹ nÄƒng nÃ y sáº½ lÃ  ná»n táº£ng Ä‘á»ƒ báº¡n lÃ m viá»‡c táº¡i cÃ¡c cÃ´ng ty cÃ´ng nghá»‡ hÃ ng Ä‘áº§u, nÆ¡i mÃ  observability lÃ  yÃªu cáº§u cÆ¡ báº£n, khÃ´ng pháº£i luxury.

---

**BÃ¡o cÃ¡o hoÃ n thÃ nh! Sáºµn sÃ ng trÃ¬nh bÃ y cho giÃ¡o viÃªn ğŸš€**
